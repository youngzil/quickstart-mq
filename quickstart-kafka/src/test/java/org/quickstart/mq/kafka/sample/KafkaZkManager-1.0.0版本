import com.wacai.hermes.bridge.config.AppConfig;
import kafka.utils.ZkUtils;
import org.apache.kafka.common.utils.Time;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Service;
import scala.collection.JavaConversions;
import scala.collection.Seq;

import javax.annotation.PostConstruct;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

@Service
public class KafkaZkManager {
    private final Logger LOG = LoggerFactory.getLogger(getClass());

    private ZkUtils zkUtils;

    @PostConstruct
    private void init() {
        zkUtils = ZkUtils.withMetrics(AppConfig.kafkaZkServer, 30000, 30000, false, Time.SYSTEM);
    }

    /**
     * 从kafka的ZK拉取所有topic的分区数据
     *
     * @return
     */
    public ConcurrentHashMap<String, Integer> getAllTopicPartitionNum() {
        ConcurrentHashMap<String, Integer> result = new ConcurrentHashMap<>();
        try {
            scala.collection.mutable.Map<String, scala.collection.Map<Object, Seq<Object>>>
                destPartitionAssignmentForTopics = zkUtils.getPartitionAssignmentForTopics(zkUtils.getAllTopics());
            Map<String, scala.collection.Map<Object, Seq<Object>>> map =
                JavaConversions.mapAsJavaMap(destPartitionAssignmentForTopics);
            for (Map.Entry<String, scala.collection.Map<Object, Seq<Object>>> item : map.entrySet()) {
                result.put(item.getKey(), JavaConversions.mapAsJavaMap(item.getValue()).size());
            }
        } catch (Exception e) {
            LOG.error(e.getMessage(), e);
        }
        return result;
    }

}
